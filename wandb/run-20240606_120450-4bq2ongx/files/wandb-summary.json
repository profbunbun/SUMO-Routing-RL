{"cumulative_reward": -0.2, "epsilon": 0.9964057546272249, "episode": 9, "agent_steps": 1, "simulation_steps": 1.0, "Distance": 0, "_timestamp": 1717689893.5138614, "_runtime": 3.422685384750366, "_step": 9, "_wandb": {"runtime": 3}}