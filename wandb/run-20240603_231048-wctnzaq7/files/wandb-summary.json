{"cumulative_reward": -0.2, "epsilon": 0.9996, "episode": 1, "agent_steps": 5, "simulation_steps": 5.0, "Distance": 463, "_timestamp": 1717470794.4248412, "_runtime": 145.81176209449768, "_step": 1}