{"cumulative_reward": -0.2, "epsilon": 0.7685476960978158, "episode": 658, "agent_steps": 2, "simulation_steps": 2.0, "Distance": 115, "_timestamp": 1717461052.2704978, "_runtime": 34.08108878135681, "_step": 658}