{"cumulative_reward": -0.2, "epsilon": 0.9774534974295307, "episode": 57, "agent_steps": 2, "simulation_steps": 2.0, "Distance": 138, "_timestamp": 1717463876.0066912, "_runtime": 5.38463020324707, "_step": 57, "_wandb": {"runtime": 5}}