{"cumulative_reward": -0.2, "epsilon": 0.9964057546272249, "episode": 9, "agent_steps": 1, "simulation_steps": 1.0, "Distance": 0, "_timestamp": 1717690398.271756, "_runtime": 3.3680260181427, "_step": 9, "_wandb": {"runtime": 3}}