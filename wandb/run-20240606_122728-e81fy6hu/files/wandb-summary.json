{"cumulative_reward": -0.2, "epsilon": 0.9964057546272249, "episode": 9, "agent_steps": 1, "simulation_steps": 1.0, "Distance": 0, "_timestamp": 1717691266.041804, "_runtime": 17.36007809638977, "_step": 9, "_wandb": {"runtime": 17}}